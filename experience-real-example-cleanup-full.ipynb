{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "driving-kuwait",
   "metadata": {},
   "source": [
    "# 6. Cleaning Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pretty-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-isaac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e41e0-d5c2-4f1a-a69f-74bf495c0393",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* How do you clean an example dataset?\n",
    "* How do you deal with missing data?\n",
    "* How do you fix column type mismatches?\n",
    "\n",
    "**Objectives**\n",
    "* Clean an example dataset using both previously described concepts and some new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e1dba-a88a-4dbc-b002-200d08d60991",
   "metadata": {},
   "source": [
    "# Cleaning Real Data\n",
    "\n",
    "The previous lessons have focused on key concepts with toy datasets. The remaining lessons and examples will be focused on an actual dataset from the Hawaiian Ocean Time-Series (HOT) data website ([Link to HOT Data Website](https://hahana.soest.hawaii.edu/hot/hot-dogs/)). \n",
    "\n",
    "The Hawaiian Ocean Time-Series has been collecting samples from station ALOHA located just North of Oahu since 1988. The map below shows the exact location where the samples we will be using originate from.\n",
    "\n",
    "![HOT Location](https://www.soest.hawaii.edu/HOT_WOCE/img/map1image-rev2.png)\n",
    "\n",
    "(Original image from: <https://www.soest.hawaii.edu/HOT_WOCE/bath_HOT_Hawaii.html>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24904c-aa8d-4329-8132-e654b63d122c",
   "metadata": {},
   "source": [
    "Here, we will be using data from HOT between the 1st of January 2010 to the 1st of January 2020. This  data comes from bottle extractions between depths 0 to 500m. The environmental variables that we will be looking at include:\n",
    "\n",
    "| Column name     | Environmental Variable It Represents   |\n",
    "| --------------- | -------------------------------------- |\n",
    "| botid #         | Bottle ID                              |\n",
    "| date mmddyy     | Date                                   |\n",
    "| press dbar      | Pressure                               |\n",
    "| temp ITS-90     | Temperature                            |\n",
    "| csal PSS-78     | Salinity                               |\n",
    "| coxy umol/kg    | Oxygen concentration                   |\n",
    "| ph              | pH                                     |\n",
    "| phos umol/kg    | Phosphate concentration                |\n",
    "| nit umol/kg     | Nitrate + Nitrite concentration        |\n",
    "| no2 nmol/kg     | Nitrite concentration                  |\n",
    "| doc umol/kg     | Dissolved Organic Carbon concentration |\n",
    "| hbact # 1e5/ml | Heterotrophic Bacteria concentration   |\n",
    "| pbact # 1e5/ml | Prochlorococcus numbers                |\n",
    "| sbact # 1e5/ml | Synechococcus numbers                  |\n",
    "\n",
    "The data contains over 20000 individual samples. Before we analyze the data we are going to clean it up. Then, in the next lesson we will analyze and visualize it. To do this we will be using concepts we have already learned while also introducing some new concepts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-fifteen",
   "metadata": {},
   "source": [
    "## `DataFrame` Content Cleanup\n",
    "\n",
    "During our initial clean up we will only load in the first few rows of our dataset entire `DataFrame`. This will make it easier to work with and less daunting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proved-madonna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>botid #</th>\n",
       "      <th>date mmddyy</th>\n",
       "      <th>press dbar</th>\n",
       "      <th>temp ITS-90</th>\n",
       "      <th>csal PSS-78</th>\n",
       "      <th>coxy umol/kg</th>\n",
       "      <th>ph</th>\n",
       "      <th>phos umol/kg</th>\n",
       "      <th>nit umol/kg</th>\n",
       "      <th>doc umol/kg</th>\n",
       "      <th>hbact #*1e5/ml</th>\n",
       "      <th>pbact #*1e5/ml</th>\n",
       "      <th>sbact #*1e5/ml</th>\n",
       "      <th>no2 nmol/kg</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2190200124</td>\n",
       "      <td>30910</td>\n",
       "      <td>5.5</td>\n",
       "      <td>23.0629</td>\n",
       "      <td>35.2514</td>\n",
       "      <td>214.1</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2190200123</td>\n",
       "      <td>30910</td>\n",
       "      <td>59.6</td>\n",
       "      <td>23.0670</td>\n",
       "      <td>35.2506</td>\n",
       "      <td>214.6</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2190200122</td>\n",
       "      <td>30910</td>\n",
       "      <td>90.7</td>\n",
       "      <td>21.7697</td>\n",
       "      <td>35.1897</td>\n",
       "      <td>213.4</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2190200121</td>\n",
       "      <td>30910</td>\n",
       "      <td>119.4</td>\n",
       "      <td>20.7957</td>\n",
       "      <td>35.1666</td>\n",
       "      <td>208.5</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2190200120</td>\n",
       "      <td>30910</td>\n",
       "      <td>153.6</td>\n",
       "      <td>20.1517</td>\n",
       "      <td>35.2192</td>\n",
       "      <td>204.6</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      botid #  date mmddyy  press dbar  temp ITS-90  csal PSS-78  \\\n",
       "0  2190200124        30910         5.5      23.0629      35.2514   \n",
       "1  2190200123        30910        59.6      23.0670      35.2506   \n",
       "2  2190200122        30910        90.7      21.7697      35.1897   \n",
       "3  2190200121        30910       119.4      20.7957      35.1666   \n",
       "4  2190200120        30910       153.6      20.1517      35.2192   \n",
       "\n",
       "   coxy umol/kg  ph  phos umol/kg  nit umol/kg  doc umol/kg  hbact #*1e5/ml  \\\n",
       "0         214.1  -9          0.10         0.03           -9              -9   \n",
       "1         214.6  -9          0.11         0.06           -9              -9   \n",
       "2         213.4  -9          0.12         0.08           -9              -9   \n",
       "3         208.5  -9          0.15         0.50           -9              -9   \n",
       "4         204.6  -9          0.15         1.15           -9              -9   \n",
       "\n",
       "   pbact #*1e5/ml  sbact #*1e5/ml  no2 nmol/kg      \n",
       "0              -9              -9           -9 NaN  \n",
       "1              -9              -9           -9 NaN  \n",
       "2              -9              -9           -9 NaN  \n",
       "3              -9              -9           -9 NaN  \n",
       "4              -9              -9           -9 NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fe622-bd52-426e-8d25-fb1ea7b4da6c",
   "metadata": {},
   "source": [
    "From this we can see a few things:\n",
    "\n",
    "- There are a lot of -9 values\n",
    "- These actually denote Null values in the dataset\n",
    "- The last column (to the right of the no2 column) doesn't seem to contain a header or any data\n",
    "\n",
    "Both of these issues can easily be fixed using Pandas based on what we've learn previously.\n",
    "\n",
    "To start off let's fix the first problem we saw which was was the large number of -9 values in the dataset. These are especially strange for some of the columns e.g. how can there be a negative concentration of hbact i.e. heterotrophic bacteria? This is a stand in for places where no measurement was obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0e9f6-1204-4735-9b54-9d3411e19a9c",
   "metadata": {},
   "source": [
    "## 1 - Exercise: Treating -9 values as NaN values when loading data\n",
    "\n",
    "Let's put it all together now.  To start off try fixing the read_csv() method so that all -9 values are treated as NaN values. The temperature column could technically contain -9 values. However, all temperature measurements were above 0 so this is not an issue. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the code so that when we load the data any -9 value is treated as a NaN\n",
    "pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5,  <ADD YOU ANSWER HERE>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a44f1e-97e6-450f-82f7-7a36d20c26ff",
   "metadata": {},
   "source": [
    "With this we have fixed the problematic -9 values from our initial `DataFrame`.\n",
    "\n",
    "### Column with All Missing Values\n",
    "\n",
    "\n",
    "The second problem we identified was that there was an extra column (with no header) made up of only `NaN` values. This is probably an issue with the original file and if we were to take a look at the raw .csv file we find that each row ends with a ','. This causes `read_csv` to assume that there is another column with no data since it looks for a new line character (`\\n`) to denote when to start a new row.\n",
    "\n",
    "There are various methods to deal with this. However, we are going to use a relative simple method that we've already learn. As we discussed in a previous lesson pandas `DataFrame`s have a method to drop columns (or indexes) called `drop`. Where if we provide it with the correct arguments it can drop a column based on its name. Knowing this we can chain our `read_csv` method with the drop method so that we load in the blank column and then immediately remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e4dab-0920-4d45-8e81-5b0710ce61fb",
   "metadata": {},
   "source": [
    "## 2 - Exercise: Dropping the blank column\n",
    "\n",
    "The final command we will be using can be seen below. However, the columns parameter is missing any entries in its list of columns to drop. You will be fixing this by adding the name of the column that is empty (hint: the name isn't actually empty).\n",
    "\n",
    "~~~python\n",
    "pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5, na_values=-9).drop(columns=[])\n",
    "~~~\n",
    "\n",
    "To get the name of the column we will want to utilize a `DataFrame` attribute that we have already discussed that provides us with the list of names in the same order they occur in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read the data into a variable called df and print the column names \n",
    "# to find the actual name of the colunn with all missing values\n",
    "pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the code below so that you drop the blank column\n",
    "pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5).drop(columns=[<ADD NAME OF COLUMN TO REMOVE HERE>])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate all the changes you have made above into a single read_csv line and save the resulting dataframe\n",
    "# to the df variable\n",
    "df = pd.read_csv(\"./data/hot_dogs_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be82f95-fbdd-473c-b0e1-2cb7b3f8bee1",
   "metadata": {},
   "source": [
    "With this we have fixed some of the initial issues related to our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36bba3f-ce44-42dc-a32f-a6e7354f3923",
   "metadata": {},
   "source": [
    "### Adding a Row Index\n",
    "\n",
    "One final thing that we are going to do that is not quite \"clean up\" but nonetheless important is to set our index column when we load the data. We will use the 'botid #' column as an index. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327fd2e-0d37-4e17-bbef-9ab5aae6949d",
   "metadata": {},
   "source": [
    "## 3 - Exercise: Setting the index column when loading data\n",
    "\n",
    "To set the index column we can use a parameter in `read_csv` that was mentioned in a previous lesson. See if you can remember it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea854f17-67ca-4dd6-8f73-33dab3c6a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following code to take your already filtered DataFrame \n",
    "# from above and set the index column to botid #\n",
    "\n",
    "df = pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5)<ADD ANSWER HERE>\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadb23d-13c1-4081-bee6-65e8c677972d",
   "metadata": {},
   "source": [
    "With our initial cleanup done we can now save the current version of our `DataFrame` to the `df` variable. This `df` variable will be used for the next two sections. Make sure you remove the `nrows=5` parameter since we want to load the whole `DataFrame` starting in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb08f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the file\n",
    "# 2. Replace -9 with missing value\n",
    "# 3. Remove the empty column\n",
    "# 4. Set the index as the `botid #` column\n",
    "\n",
    "df = pd.read_csv(<...>)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-fairy",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-hypothesis",
   "metadata": {},
   "source": [
    "## `DataFrame` Column Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6024c2-4cbc-4250-95f8-39e37ae7c226",
   "metadata": {},
   "source": [
    "Now that we have fixed the initial issues we could glean from an initial look at the data we can take a look at the types that Pandas assumed for each of our columns. To do this we can access the .dtypes attribute.\n",
    "\n",
    "###### Python\n",
    "\n",
    "~~~python\n",
    "df.dtypes\n",
    "~~~\n",
    "\n",
    "###### Output\n",
    "\n",
    "~~~\n",
    " date mmddyy         int64\n",
    " time hhmmss         int64\n",
    " press dbar        float64\n",
    " temp ITS-90       float64\n",
    " csal PSS-78       float64\n",
    " coxy umol/kg      float64\n",
    " ph                float64\n",
    " phos umol/kg      float64\n",
    " nit umol/kg       float64\n",
    " doc umol/kg       float64\n",
    " hbact #*1e5/ml    float64\n",
    " pbact #*1e5/ml    float64\n",
    " sbact #*1e5/ml    float64\n",
    " no2 nmol/kg       float64\n",
    "dtype: object\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813569f-01d8-4436-90dd-d33bb19e7d63",
   "metadata": {},
   "source": [
    "Most of the columns have the correct type with the exception of the 'date mmddyy' column that has the int64 type. Pandas has a built in type to format date and time columns and conversion of the date column to this datetime type will help us later on.\n",
    "\n",
    "To change the type of a column from an int64 to a datetime type is a bit more difficult than chaging from an int64 to float64. This is because we both need to tell Pandas the type that we want it to convert the column's data to and the format that it is. For our data this is MMDDYY which we can give to Pandas using `format='%m%d%y'`. This format parameter is similar to the one used in native python. More information can be found on the `to_datetime` method doc ([Link to datetime method docs](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)).\n",
    "\n",
    "The code bit below creates a new column called 'date' that contains the same data for each row as is found in the 'date mmddyy' column but instead with the datetime64 type. It will **not** delete the original 'date mmddyy' column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a373591-42cb-4e36-a521-9784842e2567",
   "metadata": {},
   "source": [
    "###### Python\n",
    "\n",
    "~~~python\n",
    "df[\"date\"] = pd.to_datetime(df['date mmddyy'], format='%m%d%y')\n",
    "df.dtypes\n",
    "~~~\n",
    "\n",
    "###### Output\n",
    "\n",
    "~~~\n",
    "date mmddyy                int64\n",
    "time hhmmss                int64\n",
    "press dbar               float64\n",
    "temp ITS-90              float64\n",
    "csal PSS-78              float64\n",
    "coxy umol/kg             float64\n",
    "ph                       float64\n",
    "phos umol/kg             float64\n",
    "nit umol/kg              float64\n",
    "doc umol/kg              float64\n",
    "hbact #*1e5/ml           float64\n",
    "pbact #*1e5/ml           float64\n",
    "sbact #*1e5/ml           float64\n",
    "no2 nmol/kg              float64\n",
    "date              datetime64[ns]\n",
    "dtype: object\n",
    "~~~\n",
    "\n",
    "We can see from the output that we have all of our previous columns with the addition of a 'date' column with the type datetime64. If we take a look at the new column we can see that it has a different formatting compared to the 'date mmddyy' column\n",
    "\n",
    "###### Python\n",
    "\n",
    "~~~python\n",
    "df[\"date\"]\n",
    "~~~\n",
    "\n",
    "###### Output\n",
    "\n",
    "~~~\n",
    "botid #\n",
    "2190200124   2010-03-09\n",
    "2190200123   2010-03-09\n",
    "2190200122   2010-03-09\n",
    "2190200121   2010-03-09\n",
    "2190200120   2010-03-09\n",
    "                ...    \n",
    "3170200706   2019-12-20\n",
    "3170200705   2019-12-20\n",
    "3170200704   2019-12-20\n",
    "3170200703   2019-12-20\n",
    "3170200702   2019-12-20\n",
    "~~~\n",
    "Name: collection_date, Length: 21222, dtype: datetime64[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d37e298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df['date mmddyy'], format='%m%d%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c08289-3cd5-4bea-9eef-6717b1d1058e",
   "metadata": {},
   "source": [
    "Now that we've added this column (which contains the same data as found in 'date mmddyy' just in a different format) there is no need for the original date mmddyy column so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "551f0eda-8557-4518-bc79-624496f89db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"date mmddyy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-presentation",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc30359",
   "metadata": {},
   "source": [
    "### Reordering the Columns\n",
    "\n",
    "You notice the the columns in `df` are not conveiently sorted. Instead, you would like to see the columns names as:\n",
    "```\n",
    "[\n",
    " 'botid #', 'date', 'press dbar', 'temp ITS-90', 'csal PSS-78',\n",
    " 'coxy umol/kg', 'ph', 'phos umol/kg', 'nit umol/kg', 'doc umol/kg',\n",
    " 'hbact #*1e5/ml', 'pbact #*1e5/ml', 'sbact #*1e5/ml', 'no2 nmol/kg',\n",
    "] \n",
    "```       \n",
    "Given a simple dataframe as follows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ccc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472788e",
   "metadata": {},
   "source": [
    "You can reorder the columns simply by indexing into the DataFrame in the desired column order. For example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [\"B\", \"A\"]\n",
    "example_df[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7a792",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the above, can you reorder `df` so that the column order is permanently set to the following: \n",
    "\n",
    "```\n",
    "new_order = [\n",
    " 'botid #', 'date', 'press dbar', 'temp ITS-90', 'csal PSS-78',\n",
    " 'coxy umol/kg', 'ph', 'phos umol/kg', 'nit umol/kg', 'doc umol/kg',\n",
    " 'hbact #*1e5/ml', 'pbact #*1e5/ml', 'sbact #*1e5/ml', 'no2 nmol/kg',\n",
    "] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bbf957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [\n",
    " 'botid #', 'date', 'press dbar', 'temp ITS-90', 'csal PSS-78',\n",
    " 'coxy umol/kg', 'ph', 'phos umol/kg', 'nit umol/kg', 'doc umol/kg',\n",
    " 'hbact #*1e5/ml', 'pbact #*1e5/ml', 'sbact #*1e5/ml', 'no2 nmol/kg',\n",
    "] \n",
    "<Update the column order here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-garage",
   "metadata": {},
   "source": [
    "## `DataFrame` Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081269b-1f9e-4057-940c-a53fed7d1b73",
   "metadata": {},
   "source": [
    "Lastly, we will get an overview of our `DataFrame` as a final way of checking to see if anything is wrong. To do this we can use the `describe()` method which we discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of the data found in each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d638402-97d6-4eb0-99a4-b2389629757d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "With this we've clean up our initial dataset. To summarize we have:\n",
    "\n",
    "1. Replaced the -9 placeholder for Null values with NaN values.\n",
    "2. Fixed an issue with an extra column containing no data.\n",
    "3. Added a custom row index.\n",
    "4. Converted the data in 'date mmddyy' to a Pandas supported datetime type.\n",
    "5. Dropped 'date mmddyy' column since the new 'date' column contains a more appropriate data type.\n",
    "6. Reorder the column names of a dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-reliance",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c344b42-5933-4ad3-ae54-0fc842a56d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df78ccb-1afb-4b49-82f4-1fe3b2e2c7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aaf650-83bd-4cb9-9c7d-7cd1582a6649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ebfb9-458b-40f4-ab64-31b992e0b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c1381-d2a0-48c8-b80f-5634b8ed1b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67b270b2-2298-493b-89e2-e43be9ad41ec",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc5820-4cdd-4750-b164-3d00060fd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "\n",
    "# pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5,  na_values=\"-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d537086e-7506-4365-bddc-df51ab10afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "\n",
    "# pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5).columns\n",
    "# pd.read_csv(\"./data/hot_dogs_data.csv\", nrows=5).drop(columns=[\" \"])\n",
    "# df = pd.read_csv(\"./data/hot_dogs_data.csv\", na_values='NaN').drop(columns=[\" \"])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7922abf2-1ac9-48a5-9dbf-8a95d4933e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "\n",
    "# df = pd.read_csv(\"./data/hot_dogs_data.csv\", na_values='NaN').drop(columns=[\" \"])\n",
    "# df.set_index(\"botid #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90d4f4-db09-4bb9-a26a-186a4be12466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4\n",
    "\n",
    "# df[new_order]\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
